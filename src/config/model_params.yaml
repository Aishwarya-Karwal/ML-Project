
# Hyperparameter grid for some of these used models
#                 "LinearRegression": LinearRegression(),
#                 "DecisionTreeRegressor": DecisionTreeRegressor(),
#                 "RandomForestRegressor": RandomForestRegressor(),
#                 "GradientBoostingRegressor": GradientBoostingRegressor(),
#                 "KNeighborsRegressor": KNeighborsRegressor(),
#                 "XGBRegressor": XGBRegressor(),
#                 "CatBoostRegressor": CatBoostRegressor(verbose=0),
#                 "AdaBoostRegressor": AdaBoostRegressor(),

# model_params_grid:
RandomForestRegressor:
  n_estimators: [50, 100, 200]
  max_depth: [None, 10, 20, 30]
  min_samples_split: [2, 5, 10]
  min_samples_leaf: [1, 2, 4]
  bootstrap: [True, False]

XGBRegressor:
  n_estimators: [50, 100, 200]
  max_depth: [3, 6, 10]
  learning_rate: [0.01, 0.1, 0.2]
  subsample: [0.6, 0.8, 1.0]
  colsample_bytree: [0.6, 0.8, 1.0]


KNeighborsRegressor:
  n_neighbors: [3, 5, 7, 9]
  weights: ['uniform', 'distance']

GradientBoostingRegressor:
  loss : ['squared_error', 'absolute_error', 'huber', 'quantile']
  learning_rate : [0.01, 0.1, 0.2]
  n_estimators : [50, 100, 200]
  subsample : [0.6,1.0]

AdaBoostRegressor :
  loss : ['linear', 'square', 'exponential']
  n_estimators : [50, 100]
